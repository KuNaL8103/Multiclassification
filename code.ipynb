{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of Education Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=train_df, x=\"Education\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Edu_cnt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=train_df, x=\"Party\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Party_cnt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_df['Constituency ∇'].value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to convert **Total Assets** and **Liabilities** to numerical values for Data Visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverting **Total Assets** and **Liabilities** to numerical values for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uniq = []\n",
    "for i in train_df['Total Assets'].str.split():\n",
    "    uniq.append(i[-1])\n",
    "\n",
    "np.unique(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HtagAssets = []\n",
    "for i in train_df['Total Assets'].str.split():\n",
    "    x = i[-1]\n",
    "    if(x=='0'): HtagAssets.append(0)\n",
    "    elif(x=='Crore+'): HtagAssets.append(int(i[0])*10000000)\n",
    "    elif(x=='Lac+'): HtagAssets.append(int(i[0])*100000)\n",
    "    elif(x=='Thou+'): HtagAssets.append(int(i[0])*1000)\n",
    "\n",
    "train_df['Total Assets'] = HtagAssets\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uniq = []\n",
    "for i in train_df['Liabilities'].str.split():\n",
    "    uniq.append(i[-1])\n",
    "\n",
    "np.unique(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HtagLiabilities = []\n",
    "for i in train_df['Liabilities'].str.split():\n",
    "    x = i[-1]\n",
    "    if(x=='0'): HtagLiabilities.append(0)\n",
    "    elif(x=='Crore+'): HtagLiabilities.append(int(i[0])*10000000)\n",
    "    elif(x=='Lac+'): HtagLiabilities.append(int(i[0])*100000)\n",
    "    elif(x=='Thou+'): HtagLiabilities.append(int(i[0])*1000)\n",
    "    elif(x=='Hund+'): HtagLiabilities.append(int(i[0])*100)\n",
    "\n",
    "train_df['Liabilities'] = HtagLiabilities\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverting **Total Assets** and **Liabilities** to numerical values for testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uniq = []\n",
    "for i in test_df['Total Assets'].str.split():\n",
    "    uniq.append(i[-1])\n",
    "\n",
    "np.unique(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HtagAssets = []\n",
    "for i in test_df['Total Assets'].str.split():\n",
    "    x = i[-1]\n",
    "    if(x=='0'): HtagAssets.append(0)\n",
    "    elif(x=='Crore+'): HtagAssets.append(int(i[0])*10000000)\n",
    "    elif(x=='Lac+'): HtagAssets.append(int(i[0])*100000)\n",
    "    elif(x=='Thou+'): HtagAssets.append(int(i[0])*1000)\n",
    "\n",
    "test_df['Total Assets'] = HtagAssets\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "uniq = []\n",
    "for i in test_df['Liabilities'].str.split():\n",
    "    uniq.append(i[-1])\n",
    "\n",
    "np.unique(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HtagLiabilities = []\n",
    "for i in test_df['Liabilities'].str.split():\n",
    "    x = i[-1]\n",
    "    if(x=='0'): HtagLiabilities.append(0)\n",
    "    elif(x=='Crore+'): HtagLiabilities.append(int(i[0])*10000000)\n",
    "    elif(x=='Lac+'): HtagLiabilities.append(int(i[0])*100000)\n",
    "    elif(x=='Thou+'): HtagLiabilities.append(int(i[0])*1000)\n",
    "    elif(x=='Hund+'): HtagLiabilities.append(int(i[0])*100)\n",
    "\n",
    "test_df['Liabilities'] = HtagLiabilities\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if any column contains **NaN** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore, we can see that none of the values are **NaN**, so we do not need to handle it differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod = train_df\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_plot = train_df\n",
    "train_df_plot.head() # Used for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_mod = test_df\n",
    "test_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obviously, Education will not depend on **ID** and **Candidate** column. Therefore we can drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod.drop(columns=['ID','Candidate'], inplace=True)\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_mod.drop(columns=['ID','Candidate'], inplace=True)\n",
    "test_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Unique values in Constituency: \" + str(len(pd.unique(train_df_mod['Constituency ∇']))))\n",
    "print(\"Total rows of data given: \" + str(len(train_df_mod)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constituency ∇ is also almost unique for each data point. Therefore, it won't be very useful for training the model and we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod.drop(columns=['Constituency ∇'], inplace=True)\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_mod.drop(columns=['Constituency ∇'], inplace=True)\n",
    "test_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tdf1 = pd.get_dummies(train_df_mod['state'])\n",
    "train_df_mod = train_df_mod.join(tdf1)\n",
    "train_df_mod.drop(columns=['state'], inplace=True)\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tdf2 = pd.get_dummies(train_df_mod['Party'])\n",
    "train_df_mod = train_df_mod.join(tdf2)\n",
    "train_df_mod.drop(columns=['Party'], inplace=True)\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tdf1 = pd.get_dummies(test_df_mod['state'])\n",
    "test_df_mod = test_df_mod.join(tdf1)\n",
    "test_df_mod.drop(columns=['state'], inplace=True)\n",
    "test_df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tdf2 = pd.get_dummies(test_df_mod['Party'])\n",
    "test_df_mod = test_df_mod.join(tdf2)\n",
    "test_df_mod.drop(columns=['Party'], inplace=True)\n",
    "test_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df_mod['Education'] = le.fit_transform(train_df_mod['Education'])\n",
    "\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod.corrwith(train_df_mod['Education']).sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking inverse of Education column for better labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod['Education'] = le.inverse_transform(train_df_mod['Education'])\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Assets vs Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"Education\", y=\"Total Assets\", data=train_df_mod)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Total_Ass_vs_Edu.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liabilities vs Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"Education\", y=\"Liabilities\", data=train_df_mod)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Lia_vs_Edu.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criminal Case vs Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"Education\", y=\"Criminal Case\", data=train_df_mod)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Crim_case_vs_Edu.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod.drop(train_df_mod.index[train_df_mod['Criminal Case'] > 60], inplace=True)\n",
    "train_df_mod.drop(train_df_mod.index[train_df_mod['Liabilities'] > 4e9], inplace=True)\n",
    "train_df_mod.drop(train_df_mod.index[train_df_mod['Total Assets'] > 4e9], inplace=True)\n",
    "print(len(train_df_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage Distribution of Parties with the most criminal records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criminal_records = train_df_plot.groupby('Party')['Criminal Case'].sum().reset_index()\n",
    "party_counts = train_df_plot['Party'].value_counts().reset_index()\n",
    "party_counts.columns = ['Party', 'Count']\n",
    "criminal_records = pd.merge(criminal_records, party_counts, on='Party')\n",
    "criminal_records['Percentage'] = (criminal_records['Count'] / criminal_records['Count'].sum()) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Party', y='Percentage', data=criminal_records)\n",
    "ax.bar_label(ax.containers[0], rotation=90, padding=5)\n",
    "plt.xlabel(\"Party\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Fig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage Distribution of Parties with the most Wealthy Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wealthy_candidates = train_df_plot.groupby('Party')['Total Assets'].sum().reset_index()\n",
    "party_counts = train_df_plot['Party'].value_counts().reset_index()\n",
    "party_counts.columns = ['Party', 'Count']\n",
    "wealthy_candidates = pd.merge(wealthy_candidates, party_counts, on='Party')\n",
    "wealthy_candidates['Percentage'] = (wealthy_candidates['Count'] / wealthy_candidates['Count'].sum()) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Party', y='Percentage', data=wealthy_candidates)\n",
    "ax.bar_label(ax.containers[0], rotation=90, padding=5)\n",
    "plt.xlabel(\"Party\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Fig2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Assets vs Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.scatterplot(x=train_df_mod['Liabilities'], y=train_df_mod['Total Assets'])\n",
    "plt.xlabel(\"Liabilities\")\n",
    "plt.ylabel(\"Total Assets\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ax.figure.savefig(\"Fig3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_mod['Education'] = le.fit_transform(train_df_mod['Education'])\n",
    "\n",
    "train_df_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_df_mod.drop(['Education'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = train_df_mod['Education']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising number of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cols_results=['Family','Model','F1 Score']\n",
    "results = pd.DataFrame(columns=cols_results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "kVals = range(1,30)\n",
    "knn_names = ['KNN-'+str(k) for k in kVals]\n",
    "for k in kVals:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    new_row = pd.DataFrame([['KNN',knn_names[k-1],f1_score(y_test,y_pred,average='micro')]],columns=cols_results)\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "results[results.Family=='KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "model = knn.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the **F1** score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, y_predict, average=None).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(model, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_final = test_df_mod\n",
    "X_final = scaler.fit_transform(X_final)\n",
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_final = model.predict(X_final)\n",
    "y_final = le.inverse_transform(y_final)\n",
    "# X_final['Education'] = y_final\n",
    "# X_final\n",
    "test_df['Education'] = y_final\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df['ID'] = test_df.index\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df[['ID','Education']].to_csv('prediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059709,
     "sourceId": 72632,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
